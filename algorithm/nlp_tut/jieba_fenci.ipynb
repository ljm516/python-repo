{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode:  我/在/学习/自然/自然语言/语言/处理\n",
      "Default Mode:  我/在/学习/自然语言/处理\n",
      "Default Mode:  他/来到/了/网易/京研/大厦\n",
      "Search Mode:  小明/硕士/毕业/于/中国/科学/学院/科学院/中国科学院/计算/计算所/，/后/在/日本/京都/大学/日本京都大学/深造\n"
     ]
    }
   ],
   "source": [
    "# 分词，不同模式\n",
    "import jieba\n",
    "\n",
    "seg_list = jieba.cut('我在学习自然语言处理', cut_all=True)\n",
    "print('Full Mode: ', '/'.join(seg_list))  # 全模式\n",
    "\n",
    "seg_list = jieba.cut('我在学习自然语言处理', cut_all=False)\n",
    "print('Default Mode: ', '/'.join(seg_list))  # 精确模式\n",
    "\n",
    "seg_list = jieba.cut('他来到了网易京研大厦')  \n",
    "print('Default Mode: ', '/'.join(seg_list))  # 默认精确模式\n",
    "\n",
    "seg_list = jieba.cut_for_search('小明硕士毕业于中国科学院计算所，后在日本京都大学深造')\n",
    "print('Search Mode: ', '/'.join(seg_list))  # 搜索引擎模式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例，给一个篇文章分词\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import re\n",
    "import codecs\n",
    "import string\n",
    "from zhon.hanzi import punctuation\n",
    "\n",
    "# 去掉标点符号\n",
    "all_punctuation = punctuation + string.punctuation  # 中文标点符号和英文标点符号的集合\n",
    "punctuation_pattern = '[{p}]+'.format(p=all_punctuation)\n",
    "\n",
    "# 加载自定义字典和停用词\n",
    "user_dict_file = 'D:/lijiangming/docs/algorithm/library/my_corpus/my.word.dict.txt'\n",
    "jieba.load_userdict(user_dict_file)\n",
    "stop_words_file = 'D:/lijiangming/docs/algorithm/library/my_corpus/my.stop.words.txt'\n",
    "stop_words = [' ']\n",
    "with open(stop_words_file, 'r', encoding='utf-8') as fr:\n",
    "    for line in fr.readlines():\n",
    "        line = line.strip()\n",
    "        stop_words.append(line)\n",
    "\n",
    "# 加载语料，做分词\n",
    "my_corpus_file = 'D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.txt'\n",
    "out_put = ''\n",
    "total_word_count = 0\n",
    "with open(my_corpus_file, 'r', encoding='utf-8') as fr:\n",
    "    for line in fr.readlines():\n",
    "        line = line.strip()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        line = re.sub(punctuation_pattern, ' ', line)  # 去掉标点符号\n",
    "        line = line.strip(' ')\n",
    "        seg_list = jieba.cut(line, cut_all=False)\n",
    "        \n",
    "        result = []\n",
    "        for seg in seg_list:\n",
    "            if seg in stop_words:\n",
    "                continue\n",
    "            result.append(seg)\n",
    "        \n",
    "        total_word_count += len(result)\n",
    "        out_put += ' '.join(result) + '\\n'\n",
    "\n",
    "out_file = 'D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.seg.txt'\n",
    "fw = open(out_file, 'w', encoding='utf-8')\n",
    "fw.write(out_put)\n",
    "fw.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyse:  [('VIPKID', 0.46233907469779), ('蓝莓', 0.29721797659143645), ('评测', 0.23389380244254146), ('教研', 0.1651210981063536), ('机构', 0.10281262053458563), ('外教', 0.09698994260718233), ('教材', 0.09522070633414365), ('服务', 0.08854393254812154), ('在线', 0.08843672689878454), ('家长', 0.08365698062375691)]\n",
      "textrank:  []\n"
     ]
    }
   ],
   "source": [
    "# 关键词提取\n",
    "\n",
    "import codecs\n",
    "import jieba.analyse as analyse\n",
    "\n",
    "lines = codecs.open('D:/lijiangming/docs/algorithm/article/首届蓝莓大赏.txt', encoding='utf-8').read()\n",
    "\n",
    "print('analyse: ', analyse.extract_tags(lines, topK=10, withWeight=True, allowPOS=()))\n",
    "# print('lines: ', lines)\n",
    "print('textrank: ', analyse.textrank(lines, topK=20, withWeight=False, allowPOS=()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 \t r\n",
      "爱 \t v\n",
      "北京 \t ns\n",
      "天安门 \t ns\n"
     ]
    }
   ],
   "source": [
    "# 词性标注\n",
    "\n",
    "import jieba.posseg as pseg\n",
    "words = pseg.cut('我爱北京天安门')\n",
    "for word, flag in words:\n",
    "    print(word, '\\t', flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
