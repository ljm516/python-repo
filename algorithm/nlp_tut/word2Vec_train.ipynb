{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-27 13:41:35,262: INFO: training model...\n",
      "2018-06-27 13:41:35,265: INFO: collecting all words and their counts\n",
      "2018-06-27 13:41:35,268: INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-06-27 13:41:35,287: INFO: collected 3053 word types from a corpus of 11970 raw words and 18 sentences\n",
      "2018-06-27 13:41:35,290: INFO: Loading a fresh vocabulary\n",
      "2018-06-27 13:41:35,299: INFO: min_count=1 retains 3053 unique words (100% of original 3053, drops 0)\n",
      "2018-06-27 13:41:35,301: INFO: min_count=1 leaves 11970 word corpus (100% of original 11970, drops 0)\n",
      "2018-06-27 13:41:35,314: INFO: deleting the raw counts dictionary of 3053 items\n",
      "2018-06-27 13:41:35,315: INFO: sample=0.001 downsamples 46 most-common words\n",
      "2018-06-27 13:41:35,317: INFO: downsampling leaves estimated 9874 word corpus (82.5% of prior 11970)\n",
      "2018-06-27 13:41:35,327: INFO: estimated required memory for 3053 words and 100 dimensions: 3968900 bytes\n",
      "2018-06-27 13:41:35,329: INFO: resetting layer weights\n",
      "2018-06-27 13:41:35,403: INFO: training model with 2 workers on 3053 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-06-27 13:41:35,418: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-27 13:41:35,433: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-27 13:41:35,437: INFO: EPOCH - 1 : training on 11970 raw words (9868 effective words) took 0.0s, 316795 effective words/s\n",
      "2018-06-27 13:41:35,460: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-27 13:41:35,476: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-27 13:41:35,486: INFO: EPOCH - 2 : training on 11970 raw words (9897 effective words) took 0.0s, 225315 effective words/s\n",
      "2018-06-27 13:41:35,518: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-27 13:41:35,541: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-27 13:41:35,543: INFO: EPOCH - 3 : training on 11970 raw words (9879 effective words) took 0.0s, 210943 effective words/s\n",
      "2018-06-27 13:41:35,571: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-27 13:41:35,591: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-27 13:41:35,592: INFO: EPOCH - 4 : training on 11970 raw words (9918 effective words) took 0.0s, 228398 effective words/s\n",
      "2018-06-27 13:41:35,628: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-27 13:41:35,643: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-27 13:41:35,648: INFO: EPOCH - 5 : training on 11970 raw words (9861 effective words) took 0.0s, 255492 effective words/s\n",
      "2018-06-27 13:41:35,653: INFO: training on a 59850 raw words (49423 effective words) took 0.2s, 198252 effective words/s\n",
      "2018-06-27 13:41:35,657: WARNING: under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2018-06-27 13:41:35,667: INFO: save model...\n",
      "2018-06-27 13:41:35,673: INFO: saving Word2Vec object under D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.text.model, separately None\n",
      "2018-06-27 13:41:35,678: INFO: not storing attribute vectors_norm\n",
      "2018-06-27 13:41:35,681: INFO: not storing attribute cum_table\n",
      "2018-06-27 13:41:35,736: INFO: saved D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.text.model\n"
     ]
    }
   ],
   "source": [
    "# 训练语料库模型，将分词结果对应的词转成向量\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "\n",
    "logger = logging.getLogger('word2Vec_train process...')\n",
    "logging.basicConfig(format=('%(asctime)s: %(levelname)s: %(message)s'))\n",
    "logging.root.setLevel(level=logging.INFO)\n",
    "\n",
    "seg_word_file = 'D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.seg.txt'\n",
    "out_model_file = 'D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.text.model'\n",
    "\n",
    "logger.info('training model...')\n",
    "model = Word2Vec(LineSentence(seg_word_file), size=100, window=5, min_count=1, workers=2)\n",
    "\n",
    "logger.info('save model...')\n",
    "model.save(out_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-27 11:32:48,012: INFO: loading Word2Vec object from D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.text.model\n",
      "2018-06-27 11:32:48,021: INFO: loading wv recursively from D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.text.model.wv.* with mmap=None\n",
      "2018-06-27 11:32:48,022: INFO: setting ignored attribute vectors_norm to None\n",
      "2018-06-27 11:32:48,024: INFO: loading vocabulary recursively from D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.text.model.vocabulary.* with mmap=None\n",
      "2018-06-27 11:32:48,025: INFO: loading trainables recursively from D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.text.model.trainables.* with mmap=None\n",
      "2018-06-27 11:32:48,026: INFO: setting ignored attribute cum_table to None\n",
      "2018-06-27 11:32:48,028: INFO: loaded D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.text.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIPKID\t[ 0.3329409   0.08134193 -0.11953539 -0.28934497  0.39962417  0.08710035\n",
      " -0.6130515   0.19526318 -0.14418946 -0.03861113 -0.22079551 -0.05094559\n",
      " -0.21329883 -0.06570481  0.5977378   0.366204    0.04207411 -0.49885884\n",
      "  0.14802441  0.15806544  0.02693257 -0.03268153  0.36738417 -0.27391326\n",
      " -0.4165123  -0.27092597  0.77340055  0.04364326  0.695382    0.20128337\n",
      "  0.0635343  -0.04332969 -0.15539786 -0.05190161 -0.18138081 -0.0722675\n",
      " -0.35403642 -0.74074376  0.03385624  0.4485879  -0.21862657 -0.3714158\n",
      "  0.04636556  0.04635764  0.7754771  -0.43327007  0.47729978 -0.09457775\n",
      " -0.19334577 -0.03538497  0.26959366 -0.0240131  -0.4350531  -0.05296588\n",
      "  0.41148537  0.05942417 -0.6693858  -0.17847358  0.0966382  -0.10470602\n",
      "  0.36152864 -0.02380741 -0.02180869 -0.08598165 -0.03855221 -0.4171669\n",
      "  0.14490622  0.53696644 -0.0448973   0.274913    0.25561827  0.56594723\n",
      "  0.29975194  0.1274576  -0.5091291   0.17897408 -0.10721822 -0.24459949\n",
      " -0.2830593   0.3078476  -0.09172637  0.7962195  -0.2298002   0.19372506\n",
      "  0.27615702 -0.38546172 -0.372313   -0.04517892  0.17390427 -0.26428357\n",
      "  0.6381703  -0.10752726  0.31785718  0.4156064   0.05652972  0.18504207\n",
      "  0.473533   -0.31968835  0.06580449 -0.06930297]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\my-git-repo\\python\\algorithm\\env\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# 测试获取词向量\n",
    "\n",
    "import gensim\n",
    "\n",
    "model_file = 'D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.text.model'\n",
    "model = gensim.models.Word2Vec.load(model_file)\n",
    "word = 'VIPKID'\n",
    "\n",
    "try:\n",
    "    word_array = model[word]\n",
    "    print('{w}\\t{n}'.format(w=word, n=word_array))\n",
    "except KeyError as e:\n",
    "    print(e)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-27 13:42:00,043: INFO: loading Word2Vec object from D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.text.model\n",
      "2018-06-27 13:42:00,081: INFO: loading wv recursively from D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.text.model.wv.* with mmap=None\n",
      "2018-06-27 13:42:00,085: INFO: setting ignored attribute vectors_norm to None\n",
      "2018-06-27 13:42:00,091: INFO: loading vocabulary recursively from D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.text.model.vocabulary.* with mmap=None\n",
      "2018-06-27 13:42:00,097: INFO: loading trainables recursively from D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.text.model.trainables.* with mmap=None\n",
      "2018-06-27 13:42:00,100: INFO: setting ignored attribute cum_table to None\n",
      "2018-06-27 13:42:00,100: INFO: loaded D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.text.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_np_array shape: (4, 100)\n",
      "array length: 4\n",
      "new sentence np array shape: (100,)\n",
      "\"word '竖式题' not in vocabulary\"\n",
      "sentence_np_array shape: (4, 100)\n",
      "array length: 4\n",
      "new sentence np array shape: (100,)\n",
      "sentence_np_array shape: (24, 100)\n",
      "array length: 24\n",
      "new sentence np array shape: (100,)\n",
      "sentence_np_array shape: (6, 100)\n",
      "array length: 6\n",
      "new sentence np array shape: (100,)\n",
      "sentence_np_array shape: (7, 100)\n",
      "array length: 7\n",
      "new sentence np array shape: (100,)\n",
      "sentence_np_array shape: (5, 100)\n",
      "array length: 5\n",
      "new sentence np array shape: (100,)\n",
      "sentence_np_array shape: (15, 100)\n",
      "array length: 15\n",
      "new sentence np array shape: (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\my-git-repo\\python\\algorithm\\env\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "# 测试语句向量\n",
    "\n",
    "import gensim\n",
    "import jieba\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_file = 'D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.text.model'\n",
    "sentence_file = 'D:/lijiangming/docs/algorithm/library/my_corpus/sentences.txt'\n",
    "model = gensim.models.Word2Vec.load(model_file)\n",
    "\n",
    "with open(sentence_file, 'r', encoding='utf-8') as fr:\n",
    "    for line in fr.readlines():\n",
    "        sentence = line.strip()\n",
    "        word_list = jieba.lcut(sentence, cut_all=False)\n",
    "        sentence_array = []\n",
    "        for word in word_list:\n",
    "            try:\n",
    "                word_array = model[word]\n",
    "                sentence_array.append(word_array)\n",
    "            except KeyError as e:\n",
    "                print(e)\n",
    "                continue\n",
    "        \n",
    "        # n = len(word_list), m = len(word_array), 生成的句子矩阵是 n * m 维的矩阵\n",
    "        sentence_np_array = np.array(sentence_array, dtype='float')\n",
    "        print('sentence_np_array shape: {s}'.format(s=sentence_np_array.shape))\n",
    "\n",
    "        # 统一转化成 1 * m 维的矩阵\n",
    "        sum_of_array = sum(sentence_np_array)  # 矩阵求和\n",
    "#         print('sum of array: {soa}'.format(soa=sum_of_array))\n",
    "        \n",
    "        array_length = len(sentence_np_array)\n",
    "        print('array length: {al}'.format(al=array_length))\n",
    "        \n",
    "        new_sentence_np_array = sum_of_array / array_length  # 算平均数\n",
    "        print('new sentence np array shape: {nsnas}'.format(nsnas=new_sentence_np_array.shape))\n",
    "#         print('new sentence np array: {nsna}'.format(nsna=new_sentence_np_array))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
