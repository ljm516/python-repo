{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_counts shape:  (18, 2729)\n",
      "X_train_tf shape:  (18, 2729)\n",
      "idf_: [3.2512918  3.2512918  1.99852883 ... 3.2512918  3.2512918  3.2512918 ]\n",
      "X_train_tf:    (0, 2515)\t0.027520126440030136\n",
      "  (0, 2167)\t0.11008050576012055\n",
      "  (0, 2495)\t0.11756274290709895\n",
      "  (0, 489)\t0.039187580969032985\n",
      "  (0, 704)\t0.039187580969032985\n",
      "  (0, 83)\t0.039187580969032985\n",
      "  (0, 533)\t0.039187580969032985\n",
      "  (0, 2042)\t0.039187580969032985\n",
      "  (0, 1660)\t0.027520126440030136\n",
      "  (0, 520)\t0.19593790484516493\n",
      "  (0, 814)\t0.039187580969032985\n",
      "  (0, 910)\t0.0379916749161105\n",
      "  (0, 1142)\t0.022608643849789604\n",
      "  (0, 1542)\t0.016136603462262908\n",
      "  (0, 1198)\t0.10648102169713392\n",
      "  (0, 90)\t0.23409327022542784\n",
      "  (0, 599)\t0.039187580969032985\n",
      "  (0, 901)\t0.035226143491064406\n",
      "  (0, 1812)\t0.04477091350546515\n",
      "  (0, 1540)\t0.039187580969032985\n",
      "  (0, 631)\t0.035226143491064406\n",
      "  (0, 99)\t0.039187580969032985\n",
      "  (0, 267)\t0.035226143491064406\n",
      "  (0, 2609)\t0.04477091350546515\n",
      "  (0, 988)\t0.07045228698212881\n",
      "  :\t:\n",
      "  (17, 2550)\t0.07773281420388209\n",
      "  (17, 963)\t0.23319844261164627\n",
      "  (17, 965)\t0.15546562840776418\n",
      "  (17, 2382)\t0.038866407101941045\n",
      "  (17, 941)\t0.038866407101941045\n",
      "  (17, 1468)\t0.038866407101941045\n",
      "  (17, 2164)\t0.038866407101941045\n",
      "  (17, 829)\t0.038866407101941045\n",
      "  (17, 1702)\t0.07773281420388209\n",
      "  (17, 1078)\t0.038866407101941045\n",
      "  (17, 204)\t0.038866407101941045\n",
      "  (17, 2396)\t0.038866407101941045\n",
      "  (17, 2107)\t0.038866407101941045\n",
      "  (17, 1239)\t0.038866407101941045\n",
      "  (17, 1606)\t0.038866407101941045\n",
      "  (17, 2578)\t0.038866407101941045\n",
      "  (17, 2370)\t0.038866407101941045\n",
      "  (17, 94)\t0.038866407101941045\n",
      "  (17, 2285)\t0.038866407101941045\n",
      "  (17, 2481)\t0.038866407101941045\n",
      "  (17, 1908)\t0.038866407101941045\n",
      "  (17, 1168)\t0.038866407101941045\n",
      "  (17, 1302)\t0.038866407101941045\n",
      "  (17, 1303)\t0.038866407101941045\n",
      "  (17, 2582)\t0.038866407101941045\n",
      "result 1:    (0, 2167)\t0.5623939121886439\n",
      "  (0, 851)\t0.6057725227888073\n",
      "  (0, 90)\t0.5628079052103264\n",
      "round 3\n",
      "result 3:  <class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# 使用 sklearn 的词袋模型进行特征提取\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pickle\n",
    "\n",
    "my_corpus = []\n",
    "my_corpus_file= 'D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.seg.txt'\n",
    "with open(my_corpus_file, 'r', encoding='utf-8') as fr:\n",
    "    for line in fr.readlines():\n",
    "        line = line.strip()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        \n",
    "        my_corpus.append(line)\n",
    "    \n",
    "# print('my_corpus: ', my_corpus)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(my_corpus)\n",
    "print('X_train_counts shape: ', X_train_counts.shape)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print('X_train_tf shape: ', X_train_tfidf.shape)\n",
    "print(\"idf_:\" , tfidf_transformer.idf_)\n",
    "print('X_train_tf: ', X_train_tfidf)\n",
    "\n",
    "# doc_new = ['今天有几万名在中西部的美国老师的家庭的收入依靠着一家在北京运营的中国教育公司', \n",
    "#            '一位家长分享了自己孩子在VIPKID学习的故事外教老师用唱歌跳舞的方式讲课']\n",
    "doc_new = ['vipkid vipkid 美国 品牌']\n",
    "X_new_counts = count_vect.transform(doc_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "print('result 1: ', X_new_tfidf)\n",
    "pickle.dump(count_vect, open(\"D:/lijiangming/docs/algorithm/library/my_corpus/voca\",\"wb\"))\n",
    "pickle.dump(tfidf_transformer, open(\"D:/lijiangming/docs/algorithm/library/my_corpus/voca2\",\"wb\"))\n",
    "\n",
    "# print(\"round 2\")\n",
    "# count_vect = CountVectorizer()\n",
    "# X_train_counts = count_vect.fit_transform(doc_new)\n",
    "\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "# X_new_counts = count_vect.transform(doc_new)\n",
    "# X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "# print('result 2: ', X_new_tfidf)\n",
    "\n",
    "\n",
    "print(\"round 3\")\n",
    "with open(\"D:/lijiangming/docs/algorithm/library/my_corpus/voca\",\"rb\") as man_file:\n",
    "    count_vect2=pickle.load(man_file)\n",
    "with open(\"D:/lijiangming/docs/algorithm/library/my_corpus/voca2\",\"rb\") as man_file:\n",
    "    tfidf_transformer2=pickle.load(man_file)\n",
    "X_new_counts = count_vect2.transform(doc_new)\n",
    "X_new_tfidf = tfidf_transformer2.transform(X_new_counts)\n",
    "print('result 3: ', type(X_new_tfidf))\n",
    "\n",
    "# train_target = [1, 2, 1, 3, 1, 4, 5, 1, 1, 1, 1, 5, 1, 5, 1, 4, 1, 5]\n",
    "# clf = MultinomialNB().fit(X_train_tfidf, train_target)\n",
    "# predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "# for doc, category in zip(doc_new, predicted):\n",
    "#     print('{d}, {p}'.format(d=doc, p=predicted))\n",
    "\n",
    "\n",
    "# word = count_vect.get_feature_names()\n",
    "# word_weight = X_train_tf.toarray()\n",
    "# print('word size: ', len(word))\n",
    "# for i in range(len(word_weight)):\n",
    "#     print('输出第 {i} 行文本的词语 TF-IDF 权重'.format(i=i))\n",
    "#     for j in range(len(word)):\n",
    "#         print(word[j], word_weight[i][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
