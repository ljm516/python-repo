{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 sklearn 的词袋模型进行特征提取\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "my_corpus = []\n",
    "my_corpus_file= 'D:/lijiangming/docs/algorithm/library/my_corpus/my.corpus.seg.txt'\n",
    "with open(my_corpus_file, 'r', encoding='utf-8') as fr:\n",
    "    for line in fr.readlines():\n",
    "        line = line.strip()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        \n",
    "        my_corpus.append(line)\n",
    "    \n",
    "# print('my_corpus: ', my_corpus)\n",
    "\n",
    "sen=['vipkid', 'vipkid', '一点', '美国', 'jfkdkdjfkdfkdfjkd']\n",
    "count_vect = TfidfVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(sen)\n",
    "print('value 1: ', count_vect.transform(sen))\n",
    "\n",
    "# X_train_counts = \n",
    "count_vect.fit(my_corpus)\n",
    "# print('X_train_counts shape: ', X_train_counts.shape)\n",
    "# print('X_train_counts shape: ', X_train_counts)\n",
    "# print('X_train_conuts: ', X_train_counts)\n",
    "\n",
    "print('value 2: ', count_vect.transform(sen))\n",
    "\n",
    "v = count_vect.idf_\n",
    "print(\"use idf:\", count_vect.use_idf)\n",
    "print('v: ', len(v))\n",
    "print('v: ', v)\n",
    "\n",
    "# pickle.dump(v, open(\"D:/lijiangming/docs/algorithm/library/my_corpus/voca\",\"wb\"))\n",
    "\n",
    "# result = count_vect.vocabulary_.get('vipkid')\n",
    "# print('result: ', result)\n",
    "\n",
    "# feature_name = count_vect.get_feature_names()  # 特征名是所有词库中的词\n",
    "# print('feature_names: ', feature_name)\n",
    "\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "# print('X_train_tf shape: ', X_train_tfidf.shape)\n",
    "# print('X_train_tf: ', X_train_tfidf)\n",
    "# print('tf-idf voc:', tfidf_transformer.vocabulary_)\n",
    "\n",
    "# train_target = [1, 2, 1, 3, 1, 4, 5, 1, 1, 1, 1, 5, 1, 5, 1, 4, 1, 5]\n",
    "# clf = MultinomialNB().fit(X_train_tfidf, train_target)\n",
    "\n",
    "# doc_new = ['今天有几万名在中西部的美国老师的家庭的收入依靠着一家在北京运营的中国教育公司', \n",
    "#            '一位家长分享了自己孩子在VIPKID学习的故事外教老师用唱歌跳舞的方式讲课']\n",
    "# X_new_counts = count_vect.transform(doc_new)\n",
    "# X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "# predicted = clf.predict(X_new_tfidf)\n",
    "# print('predicted: ', predicted)\n",
    "\n",
    "# for doc, category in zip(doc_new, predicted):\n",
    "#     print('{d}, {p}'.format(d=doc, p=category))\n",
    "\n",
    "\n",
    "# word = count_vect.get_feature_names()\n",
    "# word_weight = X_train_tf.toarray()\n",
    "# print('word size: ', len(word))\n",
    "# for i in range(len(word_weight)):\n",
    "#     print('输出第 {i} 行文本的词语 TF-IDF 权重'.format(i=i))\n",
    "#     for j in range(len(word)):\n",
    "#         print(word[j], word_weight[i][j])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
